{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708584dd",
   "metadata": {},
   "source": [
    "Elena Georgieva\n",
    "Vocal Tuning Project\n",
    "NYU DS 1008\n",
    "Spring 2022\n",
    "GitHub: https://github.com/elenatheodora/TUNEt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81a9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from random import randrange\n",
    "import gc\n",
    "from glob import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ada7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function taken from Saksham Singh. Goal: convert my wave files to hdf (“Hierarchical Data Format”) used by Wav-U-Net\n",
    "# See: https://github.com/f90/Wave-U-Net\n",
    "# Note Groups work like dictionaries, datasets work like arrays\n",
    "def create_full_hdf_data(type='train'): # %% change train and validation here\n",
    "    fs = 44100 # sampling rate\n",
    "    A_LEN = 53929 # size of input datapoint\n",
    "    B_LEN = 44377 # size of aligned output\n",
    "    \n",
    "    path = \"/Users/elenageorgieva/Desktop/vtd/train/\" # %% change train and validation here to match above\n",
    "    \n",
    "    raw_path = path + \"raw\" # input data\n",
    "    tuned_path = path + \"output\" # output data\n",
    "    save_path = path + 'temp/' # will not change\n",
    "\n",
    "    raw_filenames = os.listdir(raw_path)\n",
    "    all_filenames = [f for f in raw_filenames]\n",
    "\n",
    "    with h5py.File(f'{save_path}{type}.hdf',\"w\") as f: # file called \"/Users/elenageorgieva/Desktop/vtd/temp/train.hdf\" in write format\n",
    "        for audio_file in all_filenames:\n",
    "            if (audio_file == \".DS_Store\"): # weird error, ignore .DS_Store file\n",
    "                continue\n",
    "            grp = f.create_group(audio_file) \n",
    "\n",
    "            x1, _ = librosa.load(path + 'raw/' + audio_file, sr=fs, mono=True) #load pair of files\n",
    "            x2, _ = librosa.load(path + 'output/' + audio_file, sr=fs, mono=True)\n",
    "\n",
    "            grp.create_dataset(\"RAW\", shape=x1.shape, dtype=x1.dtype, data=x1) \n",
    "            grp.create_dataset(\"TUNED\", shape=x2.shape, dtype=x2.dtype, data=x2) \n",
    "                 \n",
    "            len_a = x1.shape[0] \n",
    "            len_b = x2.shape[0] \n",
    "            \n",
    "            # Fix lengths by padding shorter signal \n",
    "            if(len_a > len_b): \n",
    "                librosa.util.fix_length(x2, size=len_a)\n",
    "            elif (len_b> len_a): \n",
    "                librosa.util.fix_length(x1, size=len_b)\n",
    "            \n",
    "            count = 0\n",
    "            a_list = []\n",
    "            b_list = []\n",
    "       \n",
    "            for i in range(1024):\n",
    "                start = randrange(len_a - A_LEN)\n",
    "                pad = (A_LEN - B_LEN)//2 #4776\n",
    "                if (start+A_LEN >= len_a) or (start + pad + B_LEN >= len_a) :\n",
    "                    continue\n",
    "                a_list.append([start, start+A_LEN])\n",
    "                b_list.append([start+pad, start+pad+B_LEN])\n",
    "                count += 1\n",
    "           \n",
    "            grp.attrs[\"length\"] = count # 1024\n",
    "            grp.attrs[\"fs\"] = fs # 44100\n",
    "            a_arr = np.array(a_list) # a_arr = [[5502643 5556572][6042322 6096251] etc]\n",
    "            b_arr = np.array(b_list)\n",
    "\n",
    "            grp.create_dataset(\"raw_list\", shape=a_arr.shape, dtype=a_arr.dtype, data=a_arr) #creates a data set called a_list w given shape and dtype\n",
    "            grp.create_dataset(\"tuned_list\", shape=b_arr.shape, dtype=b_arr.dtype, data=b_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f61746",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_full_hdf_data() # run above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dca6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity check, confirming hdf worked\n",
    "hdf = h5py.File(\"/Users/elenageorgieva/Desktop/vtd/train/temp/train.hdf\", 'r') # %% change train and validation here\n",
    "# print(list(hdf.keys())) # print file list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671915e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't determine # of objects (bad symbol table node signature)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print(list(hdf.keys())) # print file list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKeys: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/h5py/_hl/base.py:386\u001b[0m, in \u001b[0;36mKeysViewHDF5.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<KeysViewHDF5 \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/_collections_abc.py:805\u001b[0m, in \u001b[0;36mMappingView.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/h5py/_hl/group.py:443\u001b[0m, in \u001b[0;36mGroup.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124;03m\"\"\" Number of members attached to this group \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5g.pyx:336\u001b[0m, in \u001b[0;36mh5py.h5g.GroupID.get_num_objs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't determine # of objects (bad symbol table node signature)"
     ]
    }
   ],
   "source": [
    "print(list(hdf.keys())) # print file list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61162be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
